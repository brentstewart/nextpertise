<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloud on </title>
    <link>http://localhost:1313/tags/cloud/</link>
    <description>Recent content in Cloud on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Aug 2023 21:04:12 -0400</lastBuildDate>
    
        <atom:link href="http://localhost:1313/tags/cloud/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RIP Honeycode</title>
      <link>http://localhost:1313/230824_honeycode/</link>
      <pubDate>Thu, 24 Aug 2023 21:04:12 -0400</pubDate>
      
      <guid>http://localhost:1313/230824_honeycode/</guid>
      <description>&lt;p&gt;I got a sad little note today from Amazon - Honeycode, their no-code environment, is shutting down.  According to the post, no new signups are allowed.  Existing users have until the end of February, 2024, to pull their data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://localhost:1313/honeycode.png#floatright&#34;&gt;Honeycode Screenshot&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Honeycode was one of my early encounters with no-code environments on the web.  It had a vibe like early Access - someone with a good understanding of third normal form could pretty quickly create and join tables, design an interface, and deploy an app.  Like Access, advanced users could do some basic scripting to extend it&amp;rsquo;s capabilities.  It would automatically run in IOS, Android, and the web so your code was available anywhere.&lt;/p&gt;
&lt;p&gt;I gather that it continued to improve, but when I encountered it last summer it had some rough spots.  There wasn&amp;rsquo;t a good way to import, export, or link to outside data sources.  You couldn&amp;rsquo;t get a &amp;ldquo;configuration&amp;rdquo; description.  If you&amp;rsquo;d have been able to link this to S3 buckets and output your schema and frontend in something like YAML, I could picture a ton of people building everyday apps and sharing them on GitHub.  As it was, your app was a little lonely island.&lt;/p&gt;
&lt;p&gt;I never really saw a path to moneytize it.  You couldn&amp;rsquo;t sell an app that you created - they executed inside the Honeycode app.  You couldn&amp;rsquo;t share your app or your data.  In the end, I understand the retirement.&lt;/p&gt;
&lt;p&gt;I saw references to similar environments online in the obits, including Coda, Carrd, and Bubble.  I haven&amp;rsquo;t had time yet to check them out, but if I get the chance I&amp;rsquo;ll report back.  For the moment it&amp;rsquo;s sufficient to appreciate what Honeycode accomplished in it&amp;rsquo;s brief life and to appreciate the people who put it together.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basic Packer</title>
      <link>http://localhost:1313/221019_packer/</link>
      <pubDate>Wed, 19 Oct 2022 17:26:07 -0400</pubDate>
      
      <guid>http://localhost:1313/221019_packer/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://hashicorp.com&#34;&gt;Hashicorp&lt;/a&gt; makes some &lt;em&gt;cool&lt;/em&gt; tools for playing in the cloud or a virtualized environment, especially if you want to build out an Infrastructure as Code approach and make infrastructure updates a CI process. &lt;a href=&#34;https://packer.io&#34;&gt;Packer&lt;/a&gt; is a tool that let&amp;rsquo;s you define a server - OS, cores, storage, packages, and all - in a script that can be built on demand.  You can even define your  environment, like LAMP, in the packer script and load your application files.&lt;/p&gt;
&lt;p&gt;A very practical use of Packer would be to use it to build a custom AWS AMI for your company.  You want every EC2 instance to look like this image, so it might include security settings or agents, centralized logging setup, connections to centralized authentication, and other common resources.  I would probably load any required data files when the EC2 instance is instantiated, maybe through Cloud Formation.&lt;/p&gt;
&lt;p&gt;Packer scripts are written in HCL (Hashi Corp Language?  Dunno.), which ends up looking like YAML.&lt;/p&gt;
&lt;p&gt;I built a Packer repo that builds a simple Ubuntu server for VMWare Workstation.  It should be simple enough to customize this, including having it output an AWS AMI (Amazon Machine Image). It is tested and works with Pop! 22.04 with a 5.19 kernel and VMWare Workstation 16.2.4.&lt;/p&gt;
&lt;p&gt;The packer file (&lt;em&gt;custom.pkr.hcl&lt;/em&gt; in my example) can be broken into three parts.  The first section defines the virtual machine, including the installation media and the CD image with customization steps.  It looks like this:&lt;/p&gt;
&lt;p&gt;source &amp;ldquo;vmware-iso&amp;rdquo; &amp;ldquo;jammy-development&amp;rdquo; {
iso_urls         =[
&amp;ldquo;file:/media/brent/Ventoy/ubuntu-22.04.1-live-server-amd64.iso&amp;rdquo;,
&amp;ldquo;https://releases.ubuntu.com/22.04.1/ubuntu-22.04.1-live-server-amd64.iso&amp;rdquo;]
iso_checksum     = &amp;ldquo;sha256:10f19c5b2b8d6db711582e0e27f5116296c34fe4b313ba45f9b201a5007056cb&amp;rdquo;
iso_target_path  = &amp;ldquo;/media/brent/Ventoy&amp;rdquo;
version          = &amp;ldquo;16&amp;rdquo;
memory           = 4096
cd_files = [
&amp;ldquo;./http/meta-data&amp;rdquo;,
&amp;ldquo;./http/user-data&amp;rdquo;]
cd_label = &amp;ldquo;cidata&amp;rdquo;
cpus = 1
cores = 2
disk_type_id = 0
network = &amp;ldquo;nat&amp;rdquo;
network_adapter_type = &amp;ldquo;vmxnet3&amp;rdquo;
vm_name          = &amp;ldquo;Ubuntu2204-dev&amp;rdquo;
ssh_username     = &amp;ldquo;vmadmin&amp;rdquo;
ssh_password     = &amp;ldquo;Password&amp;rdquo;
shutdown_command = &amp;ldquo;sudo shutdown -P now&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Ubuntu can be booted into an autoinstall script (&amp;ldquo;user-data&amp;rdquo; in this example).  Typically the way this is done is by placing a file (user_data in this case) into the http folder. Packer makes that folder available through a local Apache installation. However, I could not get the VM to &amp;ldquo;see&amp;rdquo; the website and draw down the file. I tried several iterations of network configuration to no avail.  One other approach I took was to take the auto-install files and place them in an ISO image, then attaching the image to the VM. To do this, I installed the cloud utilities from Ubuntu. I used cloud-localds to put the two data files into a small ISO.&lt;/p&gt;
&lt;p&gt;sudo apt install cloud-image-utils
cloud-localds ./seed.iso user-data meta-data&lt;/p&gt;
&lt;p&gt;Later I discovered that this can be done in the packer specification:&lt;/p&gt;
&lt;p&gt;cd_files = [
&amp;ldquo;./http/meta-data&amp;rdquo;,
&amp;ldquo;./http/user-data&amp;rdquo;]
cd_label = &amp;ldquo;cidata&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The second part of the packer file describes how to interact with the server as it boots.  You can actually specify &lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt; and walk through an entire installation wizard.  With Ubuntu, I found that to be fragile.  As I made changes to the network to try to get it to see the local webserver, the installation prompts changed and broke the sequence.  Instead of walking through the wizard, this script boots into the custom setup and tells it to load the autoinstall script from the CD-image.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;boot_wait = &amp;quot;5s&amp;quot;
boot_command = [
  &amp;quot;c&amp;lt;wait&amp;gt;&amp;quot;,
  &amp;quot;linux /casper/vmlinuz ds=nocloud-net s=/cidata&amp;quot;,
  &amp;quot;&amp;lt;enter&amp;gt;&amp;quot;,
  &amp;quot;initrd /casper/initrd&amp;quot;,
  &amp;quot;&amp;lt;enter&amp;gt;&amp;quot;,
  &amp;quot;boot&amp;lt;enter&amp;gt;&amp;lt;wait60&amp;gt;&amp;quot;,
  &amp;quot;yes&amp;lt;wait120&amp;gt;&amp;quot;
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}
boot_wait = &amp;ldquo;5s&amp;rdquo;
boot_command = [
&amp;ldquo;c&lt;!-- raw HTML omitted --&gt;&amp;rdquo;,
&amp;ldquo;linux /casper/vmlinuz ds=nocloud-net s=/cidata&amp;rdquo;,
&amp;ldquo;&lt;!-- raw HTML omitted --&gt;&amp;rdquo;,
&amp;ldquo;initrd /casper/initrd&amp;rdquo;,
&amp;ldquo;&lt;!-- raw HTML omitted --&gt;&amp;rdquo;,
&amp;ldquo;boot&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&amp;rdquo;,
&amp;ldquo;yes&lt;!-- raw HTML omitted --&gt;&amp;rdquo;
]
}&lt;/p&gt;
&lt;p&gt;The third piece is the autoinstall script (user-data).  This describes some of the setup attributes, like keyboard, and the initial set of packages to be loaded.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;autoinstall:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;version: 1
apt:
geoip: true
disable_components: []
preserve_sources_list: false
primary:
- arches: [amd64, i386]
uri: &lt;a href=&#34;http://us.archive.ubuntu.com/ubuntu&#34;&gt;http://us.archive.ubuntu.com/ubuntu&lt;/a&gt;
- arches: [default]
uri: &lt;a href=&#34;http://ports.ubuntu.com/ubuntu-ports&#34;&gt;http://ports.ubuntu.com/ubuntu-ports&lt;/a&gt;
early-commands:
- sudo systemctl stop ssh
locale: en_US
keyboard:
layout: us
identity:
hostname: jammy-daily
username: vmadmin
password: $6$Da/Bin6we2OOJCVD$HM00JdEP47D.cVfSYzwf71khVHPD8NqbYLGw/iXPswndEqI2TNsMELWRCt0tA2.mVMPjFZlPI0B/xOBO9OhF01
ssh:
install-server: true
allow-pw: true
packages:
- openssh-server
- open-vm-tools
- cloud-init
- whois
- zsh
- wget
- tasksel
user-data:
disable_root: false
timezone: UTC
late-commands:
- sed -i -e &amp;rsquo;s/^#?PasswordAuthentication.*/PasswordAuthentication yes/g&amp;rsquo; /target/etc/ssh/sshd_config
- echo &amp;lsquo;vmadmin ALL=(ALL) NOPASSWD:ALL&amp;rsquo; &amp;gt; /target/etc/sudoers.d/vmadmin
- curtin in-target &amp;ndash;target=/target &amp;ndash; chmod 440 /etc/sudoers.d/vmadmin
- &amp;ldquo;lvresize -v -l +100%FREE /dev/mapper/ubuntu&amp;ndash;vg-ubuntu&amp;ndash;lv&amp;rdquo;
- &amp;ldquo;resize2fs -p /dev/mapper/ubuntu&amp;ndash;vg-ubuntu&amp;ndash;lv&amp;rdquo;&lt;/p&gt;
&lt;p&gt;My repo is linked and you can grab the original files there and build on them.  Packer is free and open-source and works with a variety of local and cloud backends, including VMWare, VirtualBox, HyperV, KVM, and AWS.  This is an easy way to produce repoducable server environments and treat your servers like &amp;ldquo;cattle not cats&amp;rdquo;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Blog - Reflections after a half year</title>
      <link>http://localhost:1313/210102_hugoafter6/</link>
      <pubDate>Sat, 02 Jan 2021 11:45:16 -0500</pubDate>
      
      <guid>http://localhost:1313/210102_hugoafter6/</guid>
      <description>&lt;p&gt;I started writing this blog back in July of 2020.  There was a lot going on at that point, and yet a lot of nothing.  My employer was acquired in May and management was cut, so I was surprised to be out of job.  We were quarantining, which added a degree of difficulty to the job search, and summer is a slow time to find work anyway.  Against all this uncertainty, I wanted to do &lt;em&gt;something&lt;/em&gt; and decided to start writing.  I hoped that the blog might provide a way to establish my &lt;em&gt;bona fides&lt;/em&gt;, and if nothing else it gave me a chance to share what I was working on (since I no longer had co-workers to share with).&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s now January of 2021.  I&amp;rsquo;m employed and the blog has been going for six months.  I thought I&amp;rsquo;d take a look back at the experience of starting a blog.  Has it accomplished what I hoped?  How hard was it and what things would I change?&lt;/p&gt;
&lt;p&gt;Most posts here are technical and this article is intended to address technical things I&amp;rsquo;ve learned.  At the same time, writing is a personal expression and accomplishes personal goals, so I also want to share how this experience has worked for me.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll skip to the conclusion . . . I&amp;rsquo;ve found it valuable, technically approachable, and I think it&amp;rsquo;s something most people should consider.  With that conclusion in mind, one of the biggest challenges is trying to figure out how to get started.  There&amp;rsquo;s some good information online and the Hugo community is very supportive, but it&amp;rsquo;s mostly organized into how to accomplish small discrete tasks and not around helping communicate the big picture.  Hopefully this will encourage you to give it a try and help you avoid some of the problems that might derail you.&lt;/p&gt;
&lt;h2 id=&#34;what-i-did-well&#34;&gt;What I did well&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://d33wubrfki0l68.cloudfront.net/c38c7334cc3f23585738e40334284fddcaf03d5e/2e17c/images/hugo-logo-wide.svg#floatsmallright&#34; alt=&#34;Hugo&#34;&gt;
&lt;a href=&#34;https://gohugo.io&#34;&gt;Hugo&lt;/a&gt; is a winner.  I write articles in Markdown, which is lightly formatted plain text.  Hugo then automatically applies formatting and plugs it into the navigational structure.  Hugo takes my raw files and generates a set of set of finished static HTML files.  Because of the way Hugo works, I haven&amp;rsquo;t had to think about server infrastructure or spend a lot of time &amp;ldquo;coding&amp;rdquo;, I&amp;rsquo;ve been able to take the time I have and focus on writing.&lt;/p&gt;
&lt;p&gt;I write articles in &lt;a href=&#34;https://vscodium.com/&#34;&gt;VSCodium&lt;/a&gt;.  Microsoft&amp;rsquo;s Visual Studio is open-source and VSCodium has stripped out the telemetry.  The two products are almost perfectly equivalent, so take your pick.  VSCodium is very easy to use, once you get the hang of it.  I open my local copy of the Nextpertise repo in the left pane and a terminal below.  I typically write with &lt;strong&gt;hugo server -D&lt;/strong&gt; running so I can check output on the fly.  I used to use different products for note taking, but I&amp;rsquo;ve switched over to VSCode for that, and I could really imagine writing a longer book using VSCode and then outputting via &lt;a href=&#34;http://localhost:1313/posts/200919_pandoc_improved/&#34;&gt;pandoc&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://code.visualstudio.com/assets/images/home-git.svg#floatsmallright&#34; alt=&#34;Visual Studio Code&#34;&gt;
Blog files are kept in a local copy of a Git repository.  After I finish updating, I sync up to GitHub which backs up my files and starts the process of moving them &amp;ldquo;live&amp;rdquo;.  Like VSCodium, Git has become a central tool for me in a variety of settings.  I use it for this blog, for code that I write, for artifacts that I contribute to GNS3, and even for keeping notes (you can have a private Repo).  I&amp;rsquo;ve learned about Git, started contributing to more projects, published my first &amp;ldquo;app&amp;rdquo;, and even expirimented with CI/CD.  One of the benefits of writing the blog is that I&amp;rsquo;ve grown technically and picked up these cool tools.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dka575ofm4ao0.cloudfront.net/pages-transactional_logos/retina/89884/render-logo-dark3.png#floatsmallleft&#34; alt=&#34;Render&#34;&gt;
&lt;a href=&#34;https://render.com&#34;&gt;Render&lt;/a&gt; hosts the site, and that has been a big win.  Render hosts static sites for free, so my only cost has been the domain.  Render integrates with GitHub via a CI process, so when I sync my repository it automatically generates web content with Hugo and posts it to the Render CDN network.  I&amp;rsquo;ve had friends in different parts of the world confirm that performance is uniformly great.  Like other decisions I made early on, this has worked out to allow me to focus my time on content.&lt;/p&gt;
&lt;p&gt;So those are the big wins: Hugo, VSCodium, GitHub, and Render.  How did I decide on that workflow and set of vendors?  The truth is that I saw &lt;a href=&#34;https://www.mikedane.com/&#34;&gt;Mike Dane&amp;rsquo;s Giraffe Academy&lt;/a&gt; Hugo videos on Youtube and thought &amp;ldquo;I can do that&amp;rdquo;.  I was also starting to learn Python and had been fooling around with Visual Studio.  GitHub was something I&amp;rsquo;d been using for a while, especially to work with the GNS3 project, but I&amp;rsquo;d been using it more at work as well.  It really just all came together.  One of the things that I think I did right was I didn&amp;rsquo;t over-analyze things.  I expirimented enough to make sure that I had a good plan and then I just went for it.&lt;/p&gt;
&lt;p&gt;Would I revisit any of these decisions?  There are several static site generator alternatives (the other one I hear most about is Jekyll), but so far I&amp;rsquo;ve been able to do everything I want with Hugo.  I expirimented with hosting in &lt;a href=&#34;http://localhost:1313/posts/200728_s3review/&#34;&gt;AWS S3&lt;/a&gt; and AWS offers this free in the first year.  &lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt; is similar to Render in that it too focuses on the JAMStack space.  Netlify has a lot of good technical documentation and videos of lectures, and they sponsor and participate in the community.  I think all three would have been good options, but for me at this point: it&amp;rsquo;s not broke.  I think that is really the magic of Render: the technical and financial barrier to doing this was significantly lowered, and that encouraged me to start and has allowed me to focus on the part I enjoy since.&lt;/p&gt;
&lt;p&gt;Another of my early decisions that has really born fruit - making my own CSS and theme.  Hugo allows you to clone a theme from GitHub.  As I mentioned earlier, the Hugo community is very supportive and there are a lot of themes shared via their &lt;a href=&#34;https://themes.gohugo.io/&#34;&gt;gallery&lt;/a&gt;.  I initially started with someone else&amp;rsquo;s theme, but I quickly realized that it was going to take a lot of work to understand how it all fit together.  This was particularly true because I don&amp;rsquo;t have a lot of background in web design.  The Giraffe Academy videos are really good and Mike gets into the early stages of developing a theme there.  I used some of the Giraffe Academy ideas as a basic theme and built up from there.  I&amp;rsquo;ve been able to leverage the blog to learn HTML and CSS.  The theme generally get&amp;rsquo;s more complicated because I want to solve a new problem, so &amp;ldquo;rolling my own&amp;rdquo; has allowed me to grow with the site.&lt;/p&gt;
&lt;h2 id=&#34;what-i-would-change&#34;&gt;What I would change&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png#floatsmallright&#34; alt=&#34;Google&#34;&gt;
My biggest issue has been building readership.  I still don&amp;rsquo;t think I&amp;rsquo;ve got a great handle on how to do that.  Google and Bing make it easy to register your page with them so it shows up in search results.  Google also has free online classes in using their Analytics and Search portals.  I recommend you do those things, but I&amp;rsquo;m still seeing slow and steady growth in readership and not a big growth.  Because the site isn&amp;rsquo;t widely read, it really didn&amp;rsquo;t get my name out when I was job hunting.  I recommend spending some time understanding how to publicize your site.  If anyone has great ideas and could leave them in the comments, I would appreciate your thoughts!&lt;/p&gt;
&lt;p&gt;Another mistake has been setting &lt;strong&gt;draft=false&lt;/strong&gt; in the Archtype.  Turning off the &amp;ldquo;drafts&amp;rdquo; feature in Hugo has resulted in publishing pages that weren&amp;rsquo;t finished.  Yes, you will be annoyed that you forget to &amp;ldquo;publish&amp;rdquo; by setting &lt;strong&gt;draft=false&lt;/strong&gt;, but it was a dumb idea to just turn it off.&lt;/p&gt;
&lt;p&gt;Finally, when I started I didn&amp;rsquo;t really design the site for growth.  I put all the files in the &amp;ldquo;content&amp;rdquo; directory and let them pile up, making them hard to organize.  Over New Year&amp;rsquo;s, I went back and prepended dates to file names and moved everything under a &amp;ldquo;posts&amp;rdquo; subdirectory.  This also allowed me to create the &amp;ldquo;Archives&amp;rdquo; link and made curation easier.&lt;/p&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;I started the blog with two goals: sharing some cool things I&amp;rsquo;ve learned and marketing myself during a period of unemployment.  The blog  didn&amp;rsquo;t really help get a job, but it kept me busy and focused on moving forward during a potentially depressing period.  However, I&amp;rsquo;ve found it cathartic to write and I hope that people have read and found value in this work.&lt;/p&gt;
&lt;p&gt;Creating this site has also given me a &amp;ldquo;real world&amp;rdquo; case to learn about HTML and CSS, cloud hosting, and online analytics.  It&amp;rsquo;s also pushed me to get more involved in various online communities and to learn at a deeper level so I can share my conclusions here.&lt;/p&gt;
&lt;p&gt;George Carlin used to have a bit about the difference in the quality of experience betweeen &lt;em&gt;riding&lt;/em&gt; and &lt;em&gt;driving&lt;/em&gt;.  It was a funny routine, but it stuck with me (like several of his thoughts) because it was true.  Learning through necessity pushes you to go deeper and wider.  Although my day job is management, continuous detailed learning is an important part of the IT industry.&lt;/p&gt;
&lt;p&gt;This has been easy enough that I&amp;rsquo;ve thought about creating sites for my church or the Trail Life group I lead.  If you have an expertise and an interest in sharing it, I would encourage you!  Let me know how I can help!  For those of you already on the path, I&amp;rsquo;m going to continue this conversation in a second column to detail some of the cool things I&amp;rsquo;ve learned how to do!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS Changing EC2 IPs or Water Never Lies</title>
      <link>http://localhost:1313/201218_aws-changingec2ips/</link>
      <pubDate>Fri, 18 Dec 2020 20:35:31 -0500</pubDate>
      
      <guid>http://localhost:1313/201218_aws-changingec2ips/</guid>
      <description>&lt;p&gt;I had an issue that required changing the IP address of an EC2 instance.  &lt;strong&gt;The short version: you can&amp;rsquo;t change the primary IP of an EC2 instance.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;water-never-lies&#34;&gt;Water never lies&lt;/h2&gt;
&lt;p&gt;It seems intuitive to me that you can change an IP of a VM, so when asked I said &amp;ldquo;I think so&amp;rdquo;.  Turns out I answered from ignorance, but then I did a smart thing and actually tested the process to understand it better.&lt;/p&gt;
&lt;p&gt;My Dad was a builder.  One time when I was young he was questioned about grading, so he took me to the site and observed it in the rain.  Pointing out that the water ran away from the building, he said, &amp;ldquo;Water never lies&amp;rdquo;.  It seems obvious, but the older I get the more I find it profound.&lt;/p&gt;
&lt;p&gt;People &lt;em&gt;think&lt;/em&gt; a lot of things.  What someone &lt;em&gt;thinks&lt;/em&gt; will happen isn&amp;rsquo;t nearly as interesting as what actually happens.  It&amp;rsquo;s important to test our intuition against experience and continually validate and update our expectations.&lt;/p&gt;
&lt;h2 id=&#34;back-to-the-story&#34;&gt;Back to the story&lt;/h2&gt;
&lt;p&gt;To test IP address mobility in EC2, I created two t2.micro instances running Amazon Linux 2 (which we&amp;rsquo;ll call &amp;ldquo;A&amp;rdquo; and &amp;ldquo;B&amp;rdquo; for convenience). After choosing the AMI and instance type you are prompted to &amp;ldquo;Configure Instance&amp;rdquo;.  In this screen, after selecting the subnet the Network Interface details appear at the bottom of the page.  You can assign a valid unused IP - if left blank an IP will be assigned for you.  I allowed both instances to auto-assign an IP and they were assigned to the &amp;ldquo;primary&amp;rdquo; (eth0) interface.&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/AWS_Conf_IP.png#floatcenter&#34; alt=&#34;AWS IP configuration&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first thing I tried to do was to change the IP at the prompt.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ifconfig eth0 192.168.255.5 netmask 255.255.255.0  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;That would work on a physical instance, but this left the instance unreachable.  After rebooting, I tried changing the IP address from the AWS console and then I tried to remove the interface.  Neither action was allowed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/AWS_Sec_IP.png#floatright&#34; alt=&#34;AWS Secondary IP&#34;&gt;
Next I assigned a secondary IP.  To do this, go to EC2 and select the instance and then select the network interface.  Under the network interface, go to the Actions button in the top right corner and select &amp;ldquo;Manage IP addresses.  In the ensuing screen, expand the &amp;ldquo;eth0&amp;rdquo; selection and you&amp;rsquo;ll see a button for &amp;ldquo;assign new IP address&amp;rdquo;.  When you add another address, AWS will limit you to only valid and available addresses on the subnet.  If the IP is used by another instance - whether active or not - you will &lt;em&gt;not&lt;/em&gt; be able to assign it.&lt;/p&gt;
&lt;p&gt;I tried removing the secondary IP and didn&amp;rsquo;t have a problem.  I was able to take the secondary IP assigned to &amp;ldquo;A&amp;rdquo;, unassign it, and put it on &amp;ldquo;B&amp;rdquo;.  This works, but on AL2 you&amp;rsquo;ll need to restart the network service before the secondary IP will be &amp;ldquo;seen&amp;rdquo;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl restart networking
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;elastic-network-interfaces&#34;&gt;Elastic Network Interfaces&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/AWS_ENI_IP.png#floatright&#34; alt=&#34;Elastic Network Interface&#34;&gt;
I also played with ENIs.  Originally, my idea was to create a new network interface, add it to the VM, and remove the old one in order to move the IP.  Again, you can&amp;rsquo;t change or delete the primary interfaces of an EC2 instance once created.&lt;/p&gt;
&lt;p&gt;However, you can create a stand-alone ENI and associate an IP with it.  &lt;em&gt;This&lt;/em&gt; can be attached to &amp;ldquo;A&amp;rdquo;, unattached, and attached to &amp;ldquo;B&amp;rdquo; without a networking restart.  In practice, it works very similar to a secondary IP.&lt;/p&gt;
&lt;p&gt;In the Instances page, look in the menu on the left under networking and find &amp;ldquo;Network Interfaces&amp;rdquo;.  From here you can click the &amp;ldquo;create network interface&amp;rdquo; button to create an independent NIC and assign it an IP.&lt;/p&gt;
&lt;p&gt;Interface IPs cannot be reassigned without deleting the instance.  Yes, you can take a snapshot before deleting, but your tolerance for that kind of risk may be limited.&lt;/p&gt;
&lt;p&gt;The best option is to construct your VPC environment so that all references are done via Fully Qualified Domain Name (FQDN).  DNS can easily be updated to point the name &amp;ldquo;server&amp;rdquo; from 10.0.0.1 to 10.0.0.2.&lt;/p&gt;
&lt;p&gt;There are places where we are forced to refernce by IP.  In such cases, I recommend using an ENI.  Disable eth0 if having two IPs bother you.  Upgrading or replacing a VM can be as easy as standing up the new version and transferring the ENI.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve found several references on the Internet to the fact that you can&amp;rsquo;t move EC2 IPs, but not a more detailed walk through of what you &lt;em&gt;can&lt;/em&gt; do.  I hope this discussion has been helpful!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS S3 Review</title>
      <link>http://localhost:1313/200728_s3review/</link>
      <pubDate>Tue, 28 Jul 2020 15:44:02 -0400</pubDate>
      
      <guid>http://localhost:1313/200728_s3review/</guid>
      <description>&lt;p&gt;In a previous post, I described hosting this website on Render.  I mentioned that I am coming up to speed on AWS and it was my intention to host the site on S3 as well.  This post documents my experience.&lt;/p&gt;
&lt;h2 id=&#34;hugo&#34;&gt;Hugo&lt;/h2&gt;
&lt;p&gt;Render has a CI-step that builds the html from Hugo auto-magically.  AWS isn’t integrated with Github, so I needed to build the website.  This is pretty easy, just navigate to the directory and type “hugo”.  This produces a “public” directory that needs to be copied to your webserver.&lt;/p&gt;
&lt;p&gt;AWS allows you to specify an error page.  In Hugo, I setup a &lt;em&gt;404.html&lt;/em&gt; page under &lt;em&gt;theme/layouts&lt;/em&gt; and used the S3 Properties page to specify that URL for the error page.&lt;/p&gt;
&lt;h2 id=&#34;aws&#34;&gt;AWS&lt;/h2&gt;
&lt;p&gt;The short version of hosting a site on S3 is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an S3 bucket&lt;/li&gt;
&lt;li&gt;The bucket needs to be public, so set &amp;ldquo;Block all public access&amp;rdquo; to OFF.&lt;/li&gt;
&lt;li&gt;Navigate to S3, select the bucket and go to the Properties tab.  Under &amp;ldquo;Static Website Hosting&amp;rdquo; select &amp;ldquo;Use this bucket to host a website&amp;rdquo;.  You can also grab the URL from this screen.  This will look something like  &lt;a href=&#34;http://mybucket.s3-website-us-east-1.amazonaws.com&#34;&gt;http://mybucket.s3-website-us-east-1.amazonaws.com&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In your DNS, setup a CNAME for www to the bucket URL.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above is pretty well documented at various places and it&amp;rsquo;s pretty easy.  So obviously, that&amp;rsquo;s not the way I did it.&lt;/p&gt;
&lt;p&gt;AWS has a feature called Cloud Formation that let&amp;rsquo;s you specify an environment in JSON or YAML.  This approach is called &lt;em&gt;Infrastructure as Code&lt;/em&gt;.  There are a lot of scenarios where IaC is useful.  It reduces the time and cost of setting up an environment, which could be useful if you wanted to quickly setup a dev environment or duplicate an environment for some other purpose.  This approach reduces errors because you can troubleshoot the setup script when you build it and then iteratively improve it.  It also allows for the environment to be specified and reviewed by security specialists, improving communication between operations and security and reducing risks.&lt;/p&gt;
&lt;p&gt;Cloud Formation is free to use.  I built a JSON &lt;a href=&#34;http://localhost:1313/CloudFormation-Setup_Public_S3.json&#34;&gt;file&lt;/a&gt; that creates an S3 bucket, marks the bucket public, and then applies a security policy.  My template also outputs the URL back to you when it completes.  The Amazon online user guide has a lot of examples I used to understand the process, plus there is a template designer that let&amp;rsquo;s you draw out your target environment a la Visio and builds the JSON for you.  I didn&amp;rsquo;t use the designer to draw, but I pasted the file I developed into the designer and it was a good way to &amp;ldquo;debug&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Doing initial development of a Cloud Formation template meant running the process several times and fixing issues.  For me, most of these were formatting.  This took a little over an hour to iron out.  When everything was ready, I instantiated my S3 web bucket and I just needed to copy my Hugo public folder into the bucket.&lt;/p&gt;
&lt;p&gt;AWS has a &amp;ldquo;free tier&amp;rdquo; that&amp;rsquo;s offered during your first 12 months.  Five gigs of S3 space is included in this tier, so the initial cost isn&amp;rsquo;t bad and S3 isn&amp;rsquo;t expensive after that.  Whether you my example to use Cloud Formation or not, this is a cheap and effective way to get a static website setup.  Amazon provides a very durable and scalable environment, there&amp;rsquo;s a ton of tools available, and it&amp;rsquo;s easy to imagine growing from this initial setup to a dynamic site using K8s.&lt;/p&gt;
&lt;p&gt;That said, updating the html feels a little clunky after using Render and it&amp;rsquo;s integration with Github.  I&amp;rsquo;m going to leave the S3 version up for a while and try some improvements.  I&amp;rsquo;d like to build a command line script to run the Cloud Formation process, run Hugo to compile the site, and then transfer files.  That seems doable and it would make this a lot easier to maintain.  AWS also has a CodeCommit repository that looks like Github from a distance.  It would be interesting to explore using CodeCommit for the site as well.&lt;/p&gt;
&lt;p&gt;For now, I&amp;rsquo;m very pleased with the Render workflow and I&amp;rsquo;ve decided to leave the &amp;ldquo;official&amp;rdquo; copy of the site there.&lt;/p&gt;
&lt;p&gt;As always, I&amp;rsquo;m interested in your experiences and suggestions!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Render</title>
      <link>http://localhost:1313/200724_render/</link>
      <pubDate>Fri, 24 Jul 2020 08:21:27 -0400</pubDate>
      
      <guid>http://localhost:1313/200724_render/</guid>
      <description>&lt;h3 id=&#34;tldr-you-should-take-a-look-at-rendercom&#34;&gt;TLDR: you should take a look at Render.com&lt;/h3&gt;
&lt;p&gt;I wrote in a previous post that I decided to build my site using Hugo, a decision I&amp;rsquo;m still really tickled with.  My initial draw to a Static Site Generator was to host my site in S3.  There&amp;rsquo;s a lot of attraction there - creating a public S3 bucket is easy, it&amp;rsquo;s low-cost, there&amp;rsquo;s no server to maintain, and the data is replicated within region between Availability Zones.  From a security perspective, S3 is easy to secure and the bucket is isolated.&lt;/p&gt;
&lt;p&gt;I have experience with the major cloud providers and my high-level opinion is that AWS is the most mature, has the most complete set of products, and is the easiest to deal with.  Plus, I&amp;rsquo;m working my way through the AWS certs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/render.png#floatright&#34; alt=&#34;Render Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;In coming up to speed on Hugo, I heard about a site called Render.  The salient points were that Render offered free static-site hosting and would pull your site from Git.  The Git integration was attractive - I had already decided to put the theme there and now I could just put the entire site there.  I decided to try Render.&lt;/p&gt;
&lt;p&gt;At the time of this writing, I&amp;rsquo;ve had a Render account for two days.  Signup was easy and didn&amp;rsquo;t require a credit card.  They support federation with Github, so I used that option and that may have made things easier later.&lt;/p&gt;
&lt;p&gt;Forcing me to give a card when I signup for something free always makes me feel like I&amp;rsquo;m being suckered into something.  In fact, I had an experience with Azure where I signed up for a &amp;ldquo;free&amp;rdquo; tier and ended up getting a big bill a couple months later so I have empirical reasons to be wary.&lt;/p&gt;
&lt;p&gt;I was super-impressed with the Git integration.  I went to Github and created a new &amp;ldquo;Nextpertise&amp;rdquo; project, then went to my Hugo directory and made it a repository and sync&amp;rsquo;d it to Github.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git init  
    $ git add .  
    $ git commit -m &amp;quot;Initial commit&amp;quot;  
    $ git remote add origin https://github.com/brentstewart/nextpertise.git  
    $ git push -f origin master  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hugo takes your markdown content and compiles it against templates to generate a public directory of html files that can be copied to a web server.  When you are ready to deploy, just run &amp;ldquo;hugo&amp;rdquo; with no options.  The caveat here is that Hugo doesn&amp;rsquo;t clear out old content first, and will just copy the new build on top of the old.  Best practice then is to delete the public directory before regenerating.  So before setting up Render, I generated the public directory and sync&amp;rsquo;d my repo to Github.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/Render_setup.png#floatsmallright&#34; alt=&#34;Render Setup&#34;&gt;&lt;/p&gt;
&lt;p&gt;From Render, I selected New &amp;ldquo;Web Service&amp;rdquo; and selected the repository I wanted to use.  Render asked for the web content directory (the &amp;ldquo;Publish directory&amp;rdquo;)  and the build command - here&amp;rsquo;s where I realized I messed up.  I went back and removed my &lt;strong&gt;public&lt;/strong&gt; directory and resync&amp;rsquo;d to Github, then used  &lt;strong&gt;hugo&lt;/strong&gt; as my build command.&lt;/p&gt;
&lt;p&gt;By default, Render published my site to &lt;strong&gt;nextpertise.onrender.com&lt;/strong&gt;, but adding a custom domain is super-easy.  The setup screen provides instructions on setting up your DNS and tests to confirm that this step is complete.  The Nextpertise DNS is at Network Solutions, so it was easy enough to add the required records and the changes replicated overnight and were working this morning.  Render automatically assigns certs and makes the site available via https (I literally did nothing to enable this feature, it &lt;em&gt;just worked&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Render can redirect traffic to unknown pages.  I setup a rule to redirect this traffic to 404.html.  In Hugo, I created a 404.html file under &lt;em&gt;theme/layouts&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When I finish this update, I&amp;rsquo;ll commit my local changes and push to Github.  Then I need to go to Render and click Manual Deploy.  Render will pull the changes, build the site using Hugo, and the new site will be online!  Render supports a build api hook, so I may look into using Githubs CI to trigger a Render deploy.  For now, I&amp;rsquo;m focused on getting enough content onto the site to make it interesting and cleaning up the look.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a screenshot of the pull and build.
&lt;img src=&#34;http://localhost:1313/Render_deploy.png#floatright&#34; alt=&#34;Render build&#34;&gt;&lt;/p&gt;
&lt;p&gt;Render deployed my site to Oregon - I wasn&amp;rsquo;t given an option, but that seems reasonable for a free service.  They mention that &amp;ldquo;lightning-fast CDN&amp;rdquo; is included and accessing the site from the eastern US does seem reasonably quick.  &lt;em&gt;If one of my friends in India reads this, could you provide some feedback on what it&amp;rsquo;s like for you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m really impressed with Render and - based on two days of playing - definitely recommend you take a look.  I still intend to deploy to S3, for comparison and to get some experience with S3, so I&amp;rsquo;ll write about that in the future.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
