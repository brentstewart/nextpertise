<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Review on Nextpertise</title>
    <link>https://www.nextpertise.net/tags/review/</link>
    <description>Recent content in Review on Nextpertise</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Aug 2020 09:12:52 -0400</lastBuildDate>
    
        <atom:link href="https://www.nextpertise.net/tags/review/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux Home Cloud Backup</title>
      <link>https://www.nextpertise.net/homebackup/</link>
      <pubDate>Tue, 04 Aug 2020 09:12:52 -0400</pubDate>
      
      <guid>https://www.nextpertise.net/homebackup/</guid>
      <description>&lt;p&gt;At one point, I was taught to divide tasks by priority A, B, C.  As I&amp;rsquo;ve gotten older, I&amp;rsquo;ve converted that scale into &amp;ldquo;things that will immediately get me fired or divorced&amp;rdquo;, &amp;ldquo;things that will eventually get me fired or divorced&amp;rdquo;, and &amp;ldquo;things I&amp;rsquo;d like to do if I have time&amp;rdquo;.  One of the &amp;ldquo;A&amp;rdquo; tasks on this scale is making sure that we don&amp;rsquo;t lose our family digital pictures!&lt;/p&gt;
&lt;p&gt;Our home file server is an Ubuntu VM.  Over the years, I&amp;rsquo;ve used a variety of strategies to maintain personal backups.  Recently, I felt the time was right to move to cloud based backup - both for the convenience and the security of having things off-site.  I considered AWS S3, but Backblaze offers a similar and less-expensive service.  A former employer used Backblaze for laptop backups and I administered that system, and I always felt they did a good job and were reasonable to work with.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.nextpertise.net/BB_bucket_setup.png#floatright&#34; alt=&#34;Backblaze Dashboard&#34;&gt;  I settled on using Duplicati for the backkup software.  Duplicati runs on everything (Linux + various less secure OS), has a DEB, and is FOSS.  Duplicati has built in support for cloud backup, including Backblaze and S3.  I have a friend that uses Duplicati and it&amp;rsquo;s discussed on Jupiter Broadcasting, so I wanted to give it a try.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with Backblaze.  I setup an account and configured it for 2FA.  Then I created an ID and application key at the Backblaze dashboard and setup a bucket.  You can specify the bucket policy, and I recommend keeping older copies to protect against crypto-locking malware.  I setup my bucket to retain older copies for 180 days.&lt;/p&gt;
&lt;p&gt;Setting up Duplicati is as easy as installing the DEB and enabling the app to autostart.  My server runs Mate, so I opened the Control Center (alt&amp;ndash;f2, &amp;ldquo;mate-control-center&amp;rdquo;) and added Duplicati to the autoruns (at the bottom of the control center window).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.nextpertise.net/Mate-autorun-Duplicati.png#floatleft&#34; alt=&#34;Mate Autorun&#34;&gt; Once running, Duplicati shows a menu-bar applet. The application is administered from a web page on port 8200.  This webpage can be accessible from other machines and I usually manage the backups from my desktop.  Duplicati has excellent documentation on their website, but I was able to get it up and running quickly without investing a lot of time.&lt;/p&gt;
&lt;p&gt;From the initial Duplicati page choose &amp;ldquo;Add backup&amp;rdquo; and a wizard will walk you through specifying the details.  Make sure you keep track of the passphrase used by the backup!  Here&amp;rsquo;s a quick rundown on the selections I used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General - AES-256 Encryption.  Other options are no encryption and GNU Privacy Guard.  I don&amp;rsquo;t protect nuclear secrets, but I get itchy not encrypting data at rest, so I definitely don&amp;rsquo;t recommend that option.  I don&amp;rsquo;t know much about GNU PG, but AES-256 is considered a solid and well researched encryption so I used it.&lt;/li&gt;
&lt;li&gt;Backup destination - this is where you&amp;rsquo;ll plug in the ID and Key you generated at Backblaze earlier.&lt;/li&gt;
&lt;li&gt;Source data - gives you a file tree to select what you&amp;rsquo;d like to backup.  I&amp;rsquo;m cheap, so I separated out the non-private stuff into another directory (like installation ISOs) so I didn&amp;rsquo;t pay to back them up.&lt;/li&gt;
&lt;li&gt;Schedule - We&amp;rsquo;ll get into a discussion of RTO and RPO another time perhaps.  Basically, think about your cost to transfer files (with Backblaze, there is no incremental cost) and how much data you are willing to lose between backups.  I setup my schedule to run every night - with Backblaze there&amp;rsquo;s not really a reason &lt;em&gt;not to&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Options - Duplicati allows you to set the remote volume size.  I kept this at the recommended 50Mb.  Basically, it chunks your data so that it&amp;rsquo;s easier to restore and so that an adversary can&amp;rsquo;t identify individual file sizes, which could be a way that you&amp;rsquo;d leak information.  I also chose to keep all backups, again to protect against crypto-lockers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.nextpertise.net/Duplicati_Wiz.png#floatright&#34; alt=&#34;Duplicati Wizard&#34;&gt; After all that, just let it run!  My biggest knock on the combination of Duplicati and Backblaze is that there&amp;rsquo;s not an easy way to confirm backups are happening.  Backblaze has a 10 day trial and I didn&amp;rsquo;t initially put in a credit card.  To be clear, kudos to them for letting you try it and being easy to work with.  But . . . I forgot and the trial ran out and my backups stopped for several days.  Worse, I was clueless.&lt;/p&gt;
&lt;p&gt;Duplicati has options to setup a confirmation email after backups, which I recommend.  You&amp;rsquo;ll know there&amp;rsquo;s a problem when you &lt;em&gt;don&amp;rsquo;t&lt;/em&gt; get an email.  Unless you are more clever than me, that&amp;rsquo;s suboptimal but it is something.  Backblaze doesn&amp;rsquo;t have an alerting option for things that don&amp;rsquo;t happen.  I&amp;rsquo;m thinking that I could setup a Lambda to check via API, then send an SNS, but that&amp;rsquo;s for another day.&lt;/p&gt;
&lt;p&gt;Overall, I&amp;rsquo;m please with the setup and the results I&amp;rsquo;m getting and would recommend either component to someone trying to solve a similar home problem.  I don&amp;rsquo;t see a reason this wouldn&amp;rsquo;t be good for a work environment, but I&amp;rsquo;ll need to use it for a while before I feel comfortable making that a recommendation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS S3 Review</title>
      <link>https://www.nextpertise.net/s3review/</link>
      <pubDate>Tue, 28 Jul 2020 15:44:02 -0400</pubDate>
      
      <guid>https://www.nextpertise.net/s3review/</guid>
      <description>&lt;p&gt;In a previous post, I described hosting this website on Render.  I mentioned that I am coming up to speed on AWS and it was my intention to host the site on S3 as well.  This post documents my experience.&lt;/p&gt;
&lt;h2 id=&#34;hugo&#34;&gt;Hugo&lt;/h2&gt;
&lt;p&gt;Render has a CI-step that builds the html from Hugo auto-magically.  AWS isn’t integrated with Github, so I needed to build the website.  This is pretty easy, just navigate to the directory and type “hugo”.  This produces a “public” directory that needs to be copied to your webserver.&lt;/p&gt;
&lt;p&gt;AWS allows you to specify an error page.  In Hugo, I setup a &lt;em&gt;404.html&lt;/em&gt; page under &lt;em&gt;theme/layouts&lt;/em&gt; and used the S3 Properties page to specify that URL for the error page.&lt;/p&gt;
&lt;h2 id=&#34;aws&#34;&gt;AWS&lt;/h2&gt;
&lt;p&gt;The short version of hosting a site on S3 is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an S3 bucket&lt;/li&gt;
&lt;li&gt;The bucket needs to be public, so set &amp;ldquo;Block all public access&amp;rdquo; to OFF.&lt;/li&gt;
&lt;li&gt;Navigate to S3, select the bucket and go to the Properties tab.  Under &amp;ldquo;Static Website Hosting&amp;rdquo; select &amp;ldquo;Use this bucket to host a website&amp;rdquo;.  You can also grab the URL from this screen.  This will look something like  &lt;a href=&#34;http://mybucket.s3-website-us-east-1.amazonaws.com&#34;&gt;http://mybucket.s3-website-us-east-1.amazonaws.com&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In your DNS, setup a CNAME for www to the bucket URL.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above is pretty well documented at various places and it&amp;rsquo;s pretty easy.  So obviously, that&amp;rsquo;s not the way I did it.&lt;/p&gt;
&lt;p&gt;AWS has a feature called Cloud Formation that let&amp;rsquo;s you specify an environment in JSON or YAML.  This approach is called &lt;em&gt;Infrastructure as Code&lt;/em&gt;.  There are a lot of scenarios where IaC is useful.  It reduces the time and cost of setting up an environment, which could be useful if you wanted to quickly setup a dev environment or duplicate an environment for some other purpose.  This approach reduces errors because you can troubleshoot the setup script when you build it and then iteratively improve it.  It also allows for the environment to be specified and reviewed by security specialists, improving communication between operations and security and reducing risks.&lt;/p&gt;
&lt;p&gt;Cloud Formation is free to use.  I built a JSON &lt;a href=&#34;https://www.nextpertise.net/CloudFormation-Setup_Public_S3.json&#34;&gt;file&lt;/a&gt; that creates an S3 bucket, marks the bucket public, and then applies a security policy.  My template also outputs the URL back to you when it completes.  The Amazon online user guide has a lot of examples I used to understand the process, plus there is a template designer that let&amp;rsquo;s you draw out your target environment a la Visio and builds the JSON for you.  I didn&amp;rsquo;t use the designer to draw, but I pasted the file I developed into the designer and it was a good way to &amp;ldquo;debug&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Doing initial development of a Cloud Formation template meant running the process several times and fixing issues.  For me, most of these were formatting.  This took a little over an hour to iron out.  When everything was ready, I instantiated my S3 web bucket and I just needed to copy my Hugo public folder into the bucket.&lt;/p&gt;
&lt;p&gt;AWS has a &amp;ldquo;free tier&amp;rdquo; that&amp;rsquo;s offered during your first 12 months.  Five gigs of S3 space is included in this tier, so the initial cost isn&amp;rsquo;t bad and S3 isn&amp;rsquo;t expensive after that.  Whether you my example to use Cloud Formation or not, this is a cheap and effective way to get a static website setup.  Amazon provides a very durable and scalable environment, there&amp;rsquo;s a ton of tools available, and it&amp;rsquo;s easy to imagine growing from this initial setup to a dynamic site using K8s.&lt;/p&gt;
&lt;p&gt;That said, updating the html feels a little clunky after using Render and it&amp;rsquo;s integration with Github.  I&amp;rsquo;m going to leave the S3 version up for a while and try some improvements.  I&amp;rsquo;d like to build a command line script to run the Cloud Formation process, run Hugo to compile the site, and then transfer files.  That seems doable and it would make this a lot easier to maintain.  AWS also has a CodeCommit repository that looks like Github from a distance.  It would be interesting to explore using CodeCommit for the site as well.&lt;/p&gt;
&lt;p&gt;For now, I&amp;rsquo;m very pleased with the Render workflow and I&amp;rsquo;ve decided to leave the &amp;ldquo;official&amp;rdquo; copy of the site there.&lt;/p&gt;
&lt;p&gt;As always, I&amp;rsquo;m interested in your experiences and suggestions!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Render</title>
      <link>https://www.nextpertise.net/render/</link>
      <pubDate>Fri, 24 Jul 2020 08:21:27 -0400</pubDate>
      
      <guid>https://www.nextpertise.net/render/</guid>
      <description>&lt;h3 id=&#34;tldr-you-should-take-a-look-at-rendercom-&#34;&gt;TLDR: you should take a look at Render.com&lt;/h3&gt;
&lt;p&gt;I wrote in a previous post that I decided to build my site using Hugo, a decision I&amp;rsquo;m still really tickled with.  My initial draw to a Static Site Generator was to host my site in S3.  There&amp;rsquo;s a lot of attraction there - creating a public S3 bucket is easy, it&amp;rsquo;s low-cost, there&amp;rsquo;s no server to maintain, and the data is replicated within region between Availability Zones.  From a security perspective, S3 is easy to secure and the bucket is isolated.&lt;/p&gt;
&lt;p&gt;I have experience with the major cloud providers and my high-level opinion is that AWS is the most mature, has the most complete set of products, and is the easiest to deal with.  Plus, I&amp;rsquo;m working my way through the AWS certs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.nextpertise.net/render.png#floatright&#34; alt=&#34;Render Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;In coming up to speed on Hugo, I heard about a site called Render.  The salient points were that Render offered free static-site hosting and would pull your site from Git.  The Git integration was attractive - I had already decided to put the theme there and now I could just put the entire site there.  I decided to try Render.&lt;/p&gt;
&lt;p&gt;At the time of this writing, I&amp;rsquo;ve had a Render account for two days.  Signup was easy and didn&amp;rsquo;t require a credit card.  They support federation with Github, so I used that option and that may have made things easier later.&lt;/p&gt;
&lt;p&gt;Forcing me to give a card when I signup for something free always makes me feel like I&amp;rsquo;m being suckered into something.  In fact, I had an experience with Azure where I signed up for a &amp;ldquo;free&amp;rdquo; tier and ended up getting a big bill a couple months later so I have empirical reasons to be wary.&lt;/p&gt;
&lt;p&gt;I was super-impressed with the Git integration.  I went to Github and created a new &amp;ldquo;Nextpertise&amp;rdquo; project, then went to my Hugo directory and made it a repository and sync&amp;rsquo;d it to Github.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$ git init&lt;br&gt;
$ git add .&lt;br&gt;
$ git commit -m &amp;ldquo;Initial commit&amp;rdquo;&lt;br&gt;
$ git remote add origin &lt;a href=&#34;https://github.com/brentstewart/nextpertise.git&#34;&gt;https://github.com/brentstewart/nextpertise.git&lt;/a&gt;&lt;br&gt;
$ git push -f origin master&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hugo takes your markdown content and compiles it against templates to generate a public directory of html files that can be copied to a web server.  When you are ready to deploy, just run &amp;ldquo;hugo&amp;rdquo; with no options.  The caveat here is that Hugo doesn&amp;rsquo;t clear out old content first, and will just copy the new build on top of the old.  Best practice then is to delete the public directory before regenerating.  So before setting up Render, I generated the public directory and sync&amp;rsquo;d my repo to Github.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.nextpertise.net/Render_setup.png#floatright&#34; alt=&#34;Render Setup&#34;&gt;&lt;/p&gt;
&lt;p&gt;From Render, I selected New &amp;ldquo;Web Service&amp;rdquo; and selected the repository I wanted to use.  Render asked for the web content directory (the &amp;ldquo;Publish directory&amp;rdquo;)  and the build command - here&amp;rsquo;s where I realized I messed up.  I went back and removed my &lt;strong&gt;public&lt;/strong&gt; directory and resync&amp;rsquo;d to Github, then used  &lt;strong&gt;hugo&lt;/strong&gt; as my build command.&lt;/p&gt;
&lt;p&gt;By default, Render published my site to &lt;strong&gt;nextpertise.onrender.com&lt;/strong&gt;, but adding a custom domain is super-easy.  The setup screen provides instructions on setting up your DNS and tests to confirm that this step is complete.  The Nextpertise DNS is at Network Solutions, so it was easy enough to add the required records and the changes replicated overnight and were working this morning.  Render automatically assigns certs and makes the site available via https (I literally did nothing to enable this feature, it &lt;em&gt;just worked&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Render can redirect traffic to unknown pages.  I setup a rule to redirect this traffic to 404.html.  In Hugo, I created a 404.html file under &lt;em&gt;theme/layouts&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When I finish this update, I&amp;rsquo;ll commit my local changes and push to Github.  Then I need to go to Render and click Manual Deploy.  Render will pull the changes, build the site using Hugo, and the new site will be online!  Render supports a build api hook, so I may look into using Githubs CI to trigger a Render deploy.  For now, I&amp;rsquo;m focused on getting enough content onto the site to make it interesting and cleaning up the look.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a screenshot of the pull and build.
&lt;img src=&#34;https://www.nextpertise.net/Render_deploy.png#floatright&#34; alt=&#34;Render build&#34;&gt;&lt;/p&gt;
&lt;p&gt;Render deployed my site to Oregon - I wasn&amp;rsquo;t given an option, but that seems reasonable for a free service.  They mention that &amp;ldquo;lightning-fast CDN&amp;rdquo; is included and accessing the site from the eastern US does seem reasonably quick.  &lt;em&gt;If one of my friends in India reads this, could you provide some feedback on what it&amp;rsquo;s like for you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m really impressed with Render and - based on two days of playing - definitely recommend you take a look.  I still intend to deploy to S3, for comparison and to get some experience with S3, so I&amp;rsquo;ll write about that in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building this site</title>
      <link>https://www.nextpertise.net/building-this-site/</link>
      <pubDate>Mon, 20 Jul 2020 11:38:07 -0400</pubDate>
      
      <guid>https://www.nextpertise.net/building-this-site/</guid>
      <description>&lt;p&gt;This site was built using Hugo, which is a static site generator.  Hugo allows me to create templates and then write my content in markdown.  This makes it easy to update the site without having to fiddle with HTML.  It also makes updating the look and feel easy, because I can update the template and regenerate the site.&lt;/p&gt;
&lt;p&gt;Hugo is found in most distributions - for Ubuntu I installed it with &amp;ldquo;apt install hugo&amp;rdquo;.  I&amp;rsquo;ve found that running the local Hugo dev server (&amp;ldquo;hugo server -D&amp;rdquo;) and working with the files in VSCodium is a super easy way to develop.&lt;/p&gt;
&lt;p&gt;Mike Dane at Giraffe Academy has done an excellent series of videos that walk through Hugo.  Rather than repeat his work, I will tell you a little about my site.&lt;/p&gt;
&lt;p&gt;Hugo supports multiple taxonomies, but for now I&amp;rsquo;ve focused on using tags.  I&amp;rsquo;ve defined some parameters in my front matter for a github link, youtube link, and other references.  If I populate those parameters, they automatically display on the single template.  I used an HTML Grid for the list pages and set it to scale based on window width to produce a nice responsive behavior.  Hugo supports using themes and there are some great options, but I&amp;rsquo;ve chosen to build my own theme (&amp;ldquo;next&amp;rdquo;) because I wanted to understand the process.  You&amp;rsquo;re welcome to clone the theme.  Better yet, tell me what I did wrong!&lt;/p&gt;
&lt;p&gt;This website is maintained on GitHub.  If you like the theme, clone the submodule.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
